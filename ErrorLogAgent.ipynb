{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-google-genai"
      ],
      "metadata": {
        "id": "lHDaGxQBcuPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "LtTSxEI2UBFU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "from google.colab import userdata\n",
        "import json\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.pydantic_v1 import Field\n",
        "from pydantic import BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the pydantic model for our structured output\n",
        "class LogAnalysis(BaseModel):\n",
        "    severity: str = Field(description=\"The log's severity. (e.g., 'INFO', 'WARNING', 'ERROR', 'CRITICAL')\")\n",
        "    summary: str = Field(description=\"A brief, human-readable summary of the log entry.\")\n",
        "    entities: list[str] = Field(description=\"A list of key entities, such as IPs, user IDs, or error codes.\")\n",
        "    suggested_action: str = Field(description=\"A one-sentence suggested action for an administrator.\")\n",
        "\n",
        "# Initialize the LLM\n",
        "# We can use a fast model since the task is simple extraction\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-flash-latest\", temperature=0)"
      ],
      "metadata": {
        "id": "MZnH0LPRJ5W0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the Pydantic model\n",
        "class LogAnalysis(BaseModel):\n",
        "    severity: str = Field(description=\"The log's severity. (e.g., 'INFO', 'WARNING', 'ERROR', 'CRITICAL')\")\n",
        "    summary: str = Field(description=\"A brief, human-readable summary of the log entry.\")\n",
        "    entities: list[str] = Field(description=\"A list of key entities, such as IPs, user IDs, or error codes.\")\n",
        "    suggested_action: str = Field(description=\"A one-sentence suggested action for an administrator.\")\n",
        "\n",
        "# 2. Initialize the LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-flash-latest\", temperature=0)\n",
        "\n",
        "# 3. Initialize the parser\n",
        "parser = JsonOutputParser(pydantic_object=LogAnalysis)\n",
        "\n",
        "# 4. Create the prompt template\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an expert system administrator and log analyst. Your job is to analyze log entries and return a structured JSON analysis. {format_instructions}\"),\n",
        "    (\"user\", \"{log_entry}\")\n",
        "])\n",
        "\n",
        "# 5. Bind instructions\n",
        "format_instructions = parser.get_format_instructions()\n",
        "prompt_with_instructions = prompt.partial(format_instructions=format_instructions)\n",
        "\n",
        "# 6. Build the analyzer chain\n",
        "analyzer_chain = prompt_with_instructions | llm | parser\n",
        "\n",
        "# 7. Define our memory file path\n",
        "MEMORY_FILE = \"log_memory.json\"\n",
        "\n",
        "print(\"Analyzer chain and memory file path are ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4cPfGWQKWXC",
        "outputId": "856880f1-c8c0-45fe-9643-ab5c3ec96cda"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzer chain and memory file path are ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description=\"The log's severity. (e.g., 'INFO', 'WARNING', 'ERROR', 'CRITICAL')\" extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A brief, human-readable summary of the log entry.' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of key entities, such as IPs, user IDs, or error codes.' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A one-sentence suggested action for an administrator.' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_memory():\n",
        "    \"\"\"Loads the entity memory from a JSON file.\"\"\"\n",
        "    try:\n",
        "        with open(MEMORY_FILE, 'r') as f:\n",
        "            # Use defaultdict to avoid errors if an entity is new\n",
        "            return defaultdict(lambda: {'count': 0, 'history': []}, json.load(f))\n",
        "    except FileNotFoundError:\n",
        "        # Return a new empty defaultdict if the file doesn't exist\n",
        "        return defaultdict(lambda: {'count': 0, 'history': []})\n",
        "\n",
        "def save_memory(memory_data):\n",
        "    \"\"\"Saves the entity memory to a JSON file.\"\"\"\n",
        "    with open(MEMORY_FILE, 'w') as f:\n",
        "        json.dump(memory_data, f, indent=4)"
      ],
      "metadata": {
        "id": "gOAan4oPKdqD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_log_statefully(log_entry):\n",
        "    \"\"\"\n",
        "    Analyzes a log entry using a two-call process to\n",
        "    correlate it with historical memory.\n",
        "    \"\"\"\n",
        "\n",
        "    # --- 1. Load Memory ---\n",
        "    memory = load_memory()\n",
        "\n",
        "    # --- 2. Call 1: Initial Analysis ---\n",
        "    # Run the cheap analysis to find out *what* is in the log\n",
        "    try:\n",
        "        initial_analysis = analyzer_chain.invoke({\"log_entry\": log_entry})\n",
        "        entities = initial_analysis.get('entities', [])\n",
        "    except Exception as e:\n",
        "        print(f\"Error during initial analysis: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 3. Python Logic: Update Memory ---\n",
        "    context_string = \"\"\n",
        "    if entities:\n",
        "        entity_contexts = []\n",
        "        for entity in entities:\n",
        "            # Update the count and history for this entity\n",
        "            memory[entity]['count'] += 1\n",
        "            memory[entity]['history'].append(initial_analysis['summary'])\n",
        "\n",
        "            # Create a context summary for the *next* prompt\n",
        "            entity_contexts.append(\n",
        "                f\"Entity '{entity}' has been seen {memory[entity]['count']} time(s).\"\n",
        "            )\n",
        "\n",
        "        context_string = \"Historical Context: \" + \" \".join(entity_contexts)\n",
        "\n",
        "    # --- 4. Call 2: Augmented Analysis ---\n",
        "    # Now, we run the *same* agent again, but with the new memory context\n",
        "\n",
        "    augmented_prompt = f\"{context_string}\\n\\nLog Entry: {log_entry}\"\n",
        "\n",
        "    print(\"--- [Stateful Agent] ---\")\n",
        "    print(f\"Augmented Prompt: {augmented_prompt}\")\n",
        "\n",
        "    try:\n",
        "        stateful_analysis = analyzer_chain.invoke({\"log_entry\": augmented_prompt})\n",
        "    except Exception as e:\n",
        "        print(f\"Error during stateful analysis: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 5. Save Memory & Return ---\n",
        "    save_memory(memory)\n",
        "\n",
        "    # Return the *smarter*, stateful analysis\n",
        "    return stateful_analysis"
      ],
      "metadata": {
        "id": "PNSGqFd4K9Lk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_to_test = \"[2025-11-15 17:03:30] [WARNING] (SSH) Failed password attempt for user 'root' from 185.12.33.5\"\n",
        "\n",
        "print(f\"--- ANALYZING NEW LOG ---\")\n",
        "print(f\"Input: {log_to_test}\\n\")\n",
        "\n",
        "final_response = analyze_log_statefully(log_to_test)\n",
        "\n",
        "if final_response:\n",
        "    print(\"\\n--- FINAL STATEFUL RESPONSE ---\")\n",
        "    print(f\"Severity: {final_response['severity']}\")\n",
        "    print(f\"Summary: {final_response['summary']}\")\n",
        "    print(f\"Entities: {final_response['entities']}\")\n",
        "    print(f\"**Suggested Action**: {final_response['suggested_action']}**\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eJsYjfmK_L8",
        "outputId": "29c7e7b9-98e3-458a-91ad-90ca4df6a02f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- ANALYZING NEW LOG ---\n",
            "Input: [2025-11-15 17:03:30] [WARNING] (SSH) Failed password attempt for user 'root' from 185.12.33.5\n",
            "\n",
            "--- [Stateful Agent] ---\n",
            "Augmented Prompt: Historical Context: Entity 'SSH' has been seen 3 time(s). Entity 'root' has been seen 3 time(s). Entity '185.12.33.5' has been seen 3 time(s).\n",
            "\n",
            "Log Entry: [2025-11-15 17:03:30] [WARNING] (SSH) Failed password attempt for user 'root' from 185.12.33.5\n",
            "\n",
            "--- FINAL STATEFUL RESPONSE ---\n",
            "Severity: WARNING\n",
            "Summary: A persistent brute-force attack targeting the 'root' user via SSH has been detected. This is the fourth consecutive failed login attempt originating from IP address 185.12.33.5.\n",
            "Entities: ['SSH', 'root', '185.12.33.5']\n",
            "**Suggested Action**: Immediately block the source IP address (185.12.33.5) using a firewall or security tool (e.g., fail2ban) due to repeated failed attempts. Review SSH configuration to ensure root login is disabled and strong rate limiting is in place.**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_to_test = \"[2025-11-15 17:03:30] [WARNING] (SSH) Failed password attempt for user 'root' from 185.12.33.5\"\n",
        "\n",
        "print(f\"--- ANALYZING NEW LOG ---\")\n",
        "print(f\"Input: {log_to_test}\\n\")\n",
        "\n",
        "final_response = analyze_log_statefully(log_to_test)\n",
        "\n",
        "if final_response:\n",
        "    print(\"\\n--- FINAL STATEFUL RESPONSE ---\")\n",
        "    print(f\"Severity: {final_response['severity']}\")\n",
        "    print(f\"Summary: {final_response['summary']}\")\n",
        "    print(f\"Entities: {final_response['entities']}\")\n",
        "    print(f\"**Suggested Action**: {final_response['suggested_action']}**\")"
      ],
      "metadata": {
        "id": "7xnKXmR1L0mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_to_test = \"[2025-11-15 17:03:30] [WARNING] (SSH) Failed password attempt for user 'root' from 185.12.33.5\"\n",
        "\n",
        "print(f\"--- ANALYZING NEW LOG ---\")\n",
        "print(f\"Input: {log_to_test}\\n\")\n",
        "\n",
        "final_response = analyze_log_statefully(log_to_test)\n",
        "\n",
        "if final_response:\n",
        "    print(\"\\n--- FINAL STATEFUL RESPONSE ---\")\n",
        "    print(f\"Severity: {final_response['severity']}\")\n",
        "    print(f\"Summary: {final_response['summary']}\")\n",
        "    print(f\"Entities: {final_response['entities']}\")\n",
        "    print(f\"**Suggested Action**: {final_response['suggested_action']}**\")"
      ],
      "metadata": {
        "id": "gQ2Ujg8Yd9Ll"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}